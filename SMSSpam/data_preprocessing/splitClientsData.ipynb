{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59214961",
   "metadata": {},
   "source": [
    "# Description for generating data folders\n",
    "\n",
    "- In this notebook, we provide the source code of splitting datasets for the non-IID distributions in the paper.\n",
    "\n",
    "- In this scenerio, we generate the splitted clients data as `csv` files.\n",
    "\n",
    "- For the new data folder, it will be named as `[distribution]_[client_num]/[parameter_num]`, e.g. `quantity_noniid_20/alpha_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# original dataset we used in this paper\n",
    "\n",
    "data = pd.read_csv('../data/all.csv', lineterminator='\\n')\n",
    "data['label'] = data['label'].astype(int)\n",
    "\n",
    "# we random sample 26346 tweets as non-spam from twitter archive, which is equal to the number of spam\n",
    "d1 = data[data['label']==0].sample(26346, random_state=21)\n",
    "d2 = data[data['label']==1]\n",
    "\n",
    "# split the train and test dataset with the ratio of 9:1\n",
    "d1_train = d1.sample(frac=0.9, random_state=21)\n",
    "d1_test = d1[~d1.index.isin(d1_train.index)]\n",
    "d2_train = d2.sample(frac=0.9, random_state=21)\n",
    "d2_test = d2[~d2.index.isin(d2_train.index)]\n",
    "\n",
    "# get d as train dataset and d_test as test dataset\n",
    "d = pd.concat([d1_train,d2_train], ignore_index = True)\n",
    "d_test = pd.concat([d1_test,d2_test], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f051f",
   "metadata": {},
   "source": [
    "## Non-IID distributions for each client.\n",
    "\n",
    "\n",
    "Quantity based non-IID: 1 dirichlet distribution decides client size.\n",
    "\n",
    "Label based non-IID: 2 dirichlet distribution decides client size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_imbalance_new(distribution, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    for i in range(len(distribution)):\n",
    "        d_label = d[d['label'] == i]\n",
    "        d_all = len(d_label)\n",
    "        for j in range(len(distribution[i])):\n",
    "            if i == 0:\n",
    "                empty = pd.DataFrame(columns=['label', 'text', 'lang'])\n",
    "                empty.to_csv(os.path.join(save_dir, 'client{}.csv'.format(j)), index=False)\n",
    "            client_before = pd.read_csv(os.path.join(save_dir, 'client{}.csv'.format(j)), header=0)\n",
    "            num_of_allocate = round(d_all * distribution[i][j])\n",
    "#             print(len(d))\n",
    "#             print(num_of_allocate)\n",
    "            \n",
    "            if num_of_allocate <= len(d_label) and j < (len(distribution[i]) - 1):\n",
    "                client_after = d_label.sample(num_of_allocate, random_state=1)\n",
    "                #print(client_after)\n",
    "                d_label = d_label[~d_label.index.isin(client_after.index)]\n",
    "            else:\n",
    "                client_after = d_label\n",
    "                d_label = d_label[~d_label.index.isin(client_after.index)]\n",
    "#             print(len(d))\n",
    "    #         print('client:{}'.format(i))\n",
    "    #         print(num_of_allocate)\n",
    "    #         print(len(client_after))\n",
    "            client = pd.concat([client_before, client_after], ignore_index=True)\n",
    "            client.to_csv(os.path.join(save_dir, 'client{}.csv'.format(j)), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9add859",
   "metadata": {},
   "source": [
    "## Consistent label imbalance (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam and non-spam imbalance\n",
    "# we set the ratio of spam to non-spam as 4,1 ,0.25\n",
    "def spam_non_spam_imbalance(distribution, save_dir, non_spam_ratio, spam_ratio):\n",
    "    folder_dir = save_dir.split(\"alpha\")[0]\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(folder_dir)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    for i in range(len(distribution)):\n",
    "        if non_spam_ratio >= spam_ratio:\n",
    "            non_spam_train = d1_train\n",
    "            spam_train = d2_train.sample(round(len(non_spam_train)/non_spam_ratio), random_state=42)\n",
    "        else:\n",
    "            spam_train = d2_train\n",
    "            non_spam_train = d1_train.sample(round(len(spam_train)/spam_ratio), random_state=42)\n",
    "#         print(spam_train)\n",
    "#         print(non_spam_train)\n",
    "        st = len(spam_train)\n",
    "        nt = len(non_spam_train)\n",
    "        for j in range(len(distribution[i])):\n",
    "            if i == 0:\n",
    "                empty = pd.DataFrame(columns=['label', 'text', 'lang'])\n",
    "                empty.to_csv(os.path.join(save_dir, 'client{}.csv'.format(j)), index=False)\n",
    "            client_before = pd.read_csv(os.path.join(save_dir, 'client{}.csv'.format(j)), header=0)\n",
    "            spam_num_of_allocate = round(st * distribution[i][j])\n",
    "            non_spam_num_of_allocate = round(nt * distribution[i][j])\n",
    "#             print(len(d))\n",
    "#             print(num_of_allocate)\n",
    "            \n",
    "            if spam_num_of_allocate <= len(spam_train) and j < (len(distribution[i]) - 1):\n",
    "                client_after_spam = spam_train.sample(spam_num_of_allocate, random_state=1)\n",
    "                #print(client_after)\n",
    "                spam_train = spam_train[~spam_train.index.isin(client_after_spam.index)]\n",
    "            else:\n",
    "                client_after_spam = spam_train\n",
    "                spam_train = spam_train[~spam_train.index.isin(client_after_spam.index)]\n",
    "                \n",
    "            if non_spam_num_of_allocate <= len(non_spam_train) and j < (len(distribution[i]) - 1):\n",
    "                client_after_non_spam = non_spam_train.sample(non_spam_num_of_allocate, random_state=1)\n",
    "                #print(client_after)\n",
    "                non_spam_train = non_spam_train[~non_spam_train.index.isin(client_after_non_spam.index)]\n",
    "            else:\n",
    "                client_after_non_spam = non_spam_train\n",
    "                non_spam_train = non_spam_train[~non_spam_train.index.isin(client_after_non_spam.index)]\n",
    "                \n",
    "            client_after = pd.concat([client_after_spam, client_after_non_spam], ignore_index=True)\n",
    "#             print(len(d))\n",
    "#             print('client:{}'.format(j))\n",
    "#             print(spam_num_of_allocate)\n",
    "#             print(non_spam_num_of_allocate)\n",
    "#             print(len(client_after))\n",
    "            client = pd.concat([client_before, client_after], ignore_index=True)\n",
    "#             print(client)\n",
    "            \n",
    "            client.to_csv(os.path.join(save_dir, 'client{}.csv'.format(j)), index=False)\n",
    "#             if j == 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451eca98",
   "metadata": {},
   "source": [
    "## Initialization of non-IID distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f32908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_quantity_noniid(alpha, client_num, class_num, dataset):\n",
    "    for i in range(10000):\n",
    "        distribution_quantity = np.random.dirichlet([ alpha ] * client_num, 1)\n",
    "        num = 0\n",
    "        for j in distribution_quantity[0]:\n",
    "            if round(len(dataset) * j) == 0: # if there is a client has no spam or non-spam text, break\n",
    "                break\n",
    "            else:\n",
    "                num += 1\n",
    "        if num == client_num:\n",
    "            print('ok') # only if all the client has both spam and non-spam texts, return and print ok\n",
    "            break\n",
    "    # since the quantity imbalance only differ in quantity, so to keep the ratio of spam and non-spam the same, we duplicate the distribution\n",
    "    distribution_quantity = np.append(distribution_quantity,distribution_quantity,axis=0)\n",
    "    \n",
    "    return distribution_quantity\n",
    "\n",
    "def get_distribution_label_noniid(alpha, client_num, class_num, dataset):\n",
    "    for i in range(10000):\n",
    "        distribution_quantity = np.random.dirichlet([ alpha ] * client_num, class_num)\n",
    "        num = 0\n",
    "        for j in distribution_quantity[0]:\n",
    "            if round(len(dataset) * j) == 0: # if there is a client has no spam or non-spam text, break\n",
    "                break\n",
    "            else:\n",
    "                num += 1\n",
    "        if num == client_num:\n",
    "            print('ok') # only if all the client has both spam and non-spam texts, return and print ok\n",
    "            break\n",
    "    \n",
    "    return distribution_quantity\n",
    "\n",
    "def get_distribution_spam_non_spam_imbalance(alpha, client_num, class_num, dataset):\n",
    "    for i in range(10000):\n",
    "        distribution_quantity = np.random.dirichlet([ alpha ] * client_num, 1)\n",
    "        num = 0\n",
    "        for j in distribution_quantity[0]:\n",
    "            if round(len(dataset) * j) == 0: # if there is a client has no spam or non-spam text, break\n",
    "                break\n",
    "            else:\n",
    "                num += 1\n",
    "        if num == client_num:\n",
    "            print('ok') # only if all the client has both spam and non-spam texts, return and print ok\n",
    "            break\n",
    "    \n",
    "    return distribution_quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea63fc",
   "metadata": {},
   "source": [
    "## Generate all the datasets in the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d75b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"../data/exampleTrain.csv\")\n",
    "alpha_list = [0.5, 1, 5, 10]\n",
    "client_num_list = [200,20]\n",
    "class_num = 2\n",
    "data_path = '../data'\n",
    "distribution_discription_list = ['quantity_noniid', 'label_noniid', 'imbalance']\n",
    "for alpha in alpha_list:\n",
    "    for client_num in client_num_list:\n",
    "        for distribution in distribution_discription_list:\n",
    "            # in case the 0.5 in file path, we change 0.5 in path as 05 to save\n",
    "            if alpha != 0.5:\n",
    "                distribution_path = '{}_{}/alpha_{}'.format(distribution, client_num, alpha)\n",
    "            else:\n",
    "                distribution_path = '{}_{}/alpha_05'.format(distribution, client_num)\n",
    "            save_dir = os.path.join(data_path, distribution_path)\n",
    "            folder_dir = os.path.join(data_path, '{}_{}'.format(distribution, client_num))\n",
    "            if not os.path.exists(folder_dir):\n",
    "                os.mkdir(folder_dir)\n",
    "\n",
    "            if distribution == 'quantity_noniid':\n",
    "                # quantity_imbalance_new(get_distribution_quantity_noniid(1,200,2,train_dataset), save_dir='../data/quantity_200/alpha_1')\n",
    "                quantity_imbalance_new(get_distribution_quantity_noniid(alpha, client_num, class_num, train_dataset), save_dir=save_dir)\n",
    "            if distribution == 'label_noniid':\n",
    "                # quantity_imbalance_new(distribution_noniid_20_alpha5, save_dir='../data/label_distribution_noniid/20_alpha_5')\n",
    "                quantity_imbalance_new(get_distribution_label_noniid(alpha, client_num, class_num, train_dataset), save_dir=save_dir)\n",
    "            if distribution == 'imbalance' and alpha == 1:\n",
    "                if client_num == 20 :\n",
    "                    spam_non_spam_imbalance(get_distribution_spam_non_spam_imbalance(alpha, client_num, class_num, train_dataset), '../data/imbalance_20_b4/alpha1/',4,1)\n",
    "                    spam_non_spam_imbalance(get_distribution_spam_non_spam_imbalance(alpha, client_num, class_num, train_dataset), '../data/imbalance_20_b1/alpha1/',1,1)\n",
    "                    spam_non_spam_imbalance(get_distribution_spam_non_spam_imbalance(alpha, client_num, class_num, train_dataset), '../data/imbalance_20_b0_25/alpha1/',1,4)\n",
    "                if client_num == 200 :\n",
    "                    spam_non_spam_imbalance(get_distribution_spam_non_spam_imbalance(alpha, client_num, class_num, train_dataset), '../data/imbalance_200_b4/alpha1/',4,1)\n",
    "                    spam_non_spam_imbalance(get_distribution_spam_non_spam_imbalance(alpha, client_num, class_num, train_dataset), '../data/imbalance_200_b1/alpha1/',1,1)\n",
    "                    spam_non_spam_imbalance(get_distribution_spam_non_spam_imbalance(alpha, client_num, class_num, train_dataset), '../data/imbalance_200_b0_25/alpha1/',1,4)\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
